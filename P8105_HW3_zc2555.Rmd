---
title: "P8105_HW3_zc2555"
author: "Ziyu Chen"
date: "10/18/2021"
output: github_document
---

_r setup & loading packages_
```{r}
library(p8105.datasets)
data("instacart")
library(tidyverse)
library(ggplot2)
library(dplyr)
```

#Problem 1

_Q1: How many aisles are there, and which aisles are the most items ordered from?_

```{r}
aisles_count =
  instacart %>%
  count(aisle, sort=TRUE)

aisles_count
```

There are 134 aisles in the instacart dataset, fresh vegatables have the most times, which is 150609. 


_Q2: Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it_

```{r}
aisle_count = instacart %>%
  count(aisle,sort=TRUE) %>%
  filter(n>10000)

ggplot(aisle_count,aes(x=reorder(aisle, -n),y=n))+
  geom_bar(stat='identity')+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  labs(title="Count of aisles")+
  xlab("Aisles")+
  ylab("Order Count")
```

The top three aisles are fresh vegetables, fresh furit and packaged vegetables fruit.


_Q3: Make a table showing the three most popular items_


```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarise(
    product_count = n()) %>%
  mutate(
    product_rank = min_rank(-product_count)) %>%
  filter(product_rank <=3) %>%
  select(-product_rank) %>%
  knitr::kable()
```

The table above shows three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits” with number of times each product be ordered.

_Q4: make a Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table_


```{r}
mean_hour=
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
   group_by (product_name, order_dow) %>%
   summarise(mean_hour = mean(order_hour_of_day)) %>%
   pivot_wider(names_from =order_dow, values_from =mean_hour) 

colnames(mean_hour)=c('', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat')

mean_hour %>%
   knitr::kable()
```
This 2*7 table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

#Problem 2

_load the data_
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

_First, do some data cleaning_

```{r}
brfss=brfss_smart2010 %>%
  janitor::clean_names()%>%
  rename(state = locationabbr,
         county = locationdesc) %>%
  filter(topic == "Overall Health", response %in% c("Poor", "Fair", 'Good', 'Very good',"Excellent")) %>%  
   distinct() %>% 
  mutate(response = factor(response, levels=c("Poor", "Fair", 'Good', 'Very good',"Excellent")))
```

The cleaned data contains 10625 obs and 23 variables. 

_In 2002, which states were observed at 7 or more locations? What about in 2010?_
```{r}
brfss_2002= brfss %>%
  filter(year == 2002 | year ==2010) %>%
  group_by (year, state) %>%
  summarise(location_count= n_distinct(county))  %>%
  filter(location_count >=7)
   
brfss_2002

```
In 2002, 6 states were observed at 7 or more locations. They are Connecticut, Florida, Massachusetts, North Carolina, New Jersey, and Pennsylvania.

n 2010, 14 states were observed at 7 or more locations. They are California, Colorado, Florida, Florida, Massachusetts, Maryland, North Carolina, Nebraska, New Jersey, New York, Ohio, Pennsylvania, South Carolina, Texas and Washington.


_Make a “spaghetti” plot_


```{r}
brfss_excellent = brfss %>%
  filter(response == "Excellent")%>%
  mutate(data_value_sum = sample_size*data_value) %>% 
  group_by(year, state) %>%
  summarise(data_value_mean = mean(data_value)) %>% 
    select(year, state,  data_value_mean)

brfss_excellent %>%
  ggplot(aes(x = year, y = data_value_mean, group = state, color = state)) +
 geom_line()


```
Above is a “spaghetti” plot of average data value over time within a state group by state. 
_Make a two-panel plot showing_

```{r}
 brfss %>%
    filter(year == 2006 | year == 2010, 
         state == "NY") %>%
  select(year, state, response, data_value) %>%
  drop_na() %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot()+
  theme(axis.text.x = element_text(angle =90))+
   facet_grid(.~ year)
   
 
```
Above is a two-panel plot showing for distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State in the year 2006, and 2010, 

#Problem 3

_load the data_

```{r } 
accel_data = read_csv("accel_data.csv") %>%
  janitor::clean_names()%>%
 mutate(
    weekday_Weekend = ifelse(day_id %in% c(6,7), "Weekend", "Weekday"),
    week = as.integer(week),
    day_id = as.integer(day_id)
  ) %>%
  relocate (day_id, weekday_Weekend, day)
   

```



The dataset has 35 obs and have 1443 variables.  There are four date variables : ‘day_id’, ‘week’, ‘day_id’, ‘day’ , ‘weekday_end’(weekday or weekend), and 1440 activities variables which count for each minute of a 24-hour day starting at midnight. Each row is one day, and column activity_1:activity_1440 counts for each minute of a 24-hour day starting at midnight.  Weekday_weekend variable is created to indicate whether the day is weekday or weekend.

_aggregate minites per day_

```{r}
accel_data_day = accel_data %>%
  mutate(activity_sum = rowSums(across(activity_1:activity_1440))) %>% 
  select (  week, day, activity_sum) %>% 
  pivot_wider(names_from = day, values_from = activity_sum )%>% 
  select (week, Monday, Wednesday, Thursday, Friday, Saturday, Sunday)
accel_data_day  %>%
knitr::kable()
```

From the table,we can see that the among weekdays, monday the activity levels are usually not high, while Wednesday and thursday are higher, on weekends, the activity level usually drops

_24 activity time for each day_

```{r}
accel_each_day = accel_data %>%
  select(week, day, activity_1:activity_1440, day_id)%>%
 pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_time",
    values_to = "activity"
  ) %>%
  separate(activity_time, c(NA, 'activity_time'), sep = '_') %>%
  mutate(
    activity_time = as.integer(activity_time),
    day = factor(day, levels = c('Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday','Friday', 'Saturday'))) 

accel_each_day  %>%
  ggplot(aes(x = activity_time, y = activity, color = day, se=FALSE)) +
  geom_line (alpha = 0.5) +
  geom_smooth(aes(group=day), se = FALSE)+
  ylab ("total activity level")+
  xlab("Minute")
```
The x axis represents the minutes in one day, from 00:00 to 24:00 in minutes, we can see that the aggregate activity levels for each weekdays across 5 week has similar trends, as they have low activity level from 24:00 to the morning, indicating they might be sleeping. After around 500 minites (around 8 am), the activity level rises, indicating this person might get up to do something else











